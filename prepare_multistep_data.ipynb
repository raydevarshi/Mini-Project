{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olL8t2RscXkE","executionInfo":{"status":"ok","timestamp":1743076534393,"user_tz":-330,"elapsed":952,"user":{"displayName":"DEVARSHI RAY","userId":"09028434745865114586"}},"outputId":"5ea386de-e9e4-4fbf-cbf2-eb9d01c19611"},"outputs":[{"output_type":"stream","name":"stdout","text":["Multi-step training datasets created successfully!\n"]}],"source":["import numpy as np\n","\n","# Load dataset\n","X = np.load(\"/content/drive/MyDrive/mini project/X.npy\")  # Shape: (samples, 50, features)\n","y = np.load(\"/content/drive/MyDrive/mini project/y.npy\")  # Shape: (samples,)\n","\n","# Define time horizons for multi-step forecasting\n","time_horizons = [1, 3, 5, 10, 15]\n","y_multi_step = {}\n","\n","# Create multi-step target arrays\n","for T in time_horizons:\n","    X_T = X[:-T]  # Remove last T samples to match y length\n","    y_T = np.array([y[i: i+T] for i in range(len(y)-T)])  # Create T-step ahead targets\n","\n","    # Save separately for different prediction horizons\n","    np.save(f\"/content/drive/MyDrive/mini project/X_train_T{T}.npy\", X_T)\n","    np.save(f\"/content/drive/MyDrive/mini project/y_train_T{T}.npy\", y_T)\n","\n","print(\"Multi-step training datasets created successfully!\")\n"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import pickle\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","\n","# Load dataset, skipping first two rows\n","df = pd.read_csv('/content/drive/MyDrive/mini project/stock_data.csv', skiprows=2)\n","\n","# Manually set column names\n","df.columns = ['ticker', 'date', 'open', 'high', 'low', 'close', 'volume',\n","              'open_jnj', 'high_jnj', 'low_jnj', 'close_jnj', 'volume_jnj',\n","              'open_nke', 'high_nke', 'low_nke', 'close_nke', 'volume_nke']\n","\n","# Convert date column to datetime format\n","df['date'] = pd.to_datetime(df['date'])\n","\n","# Select AAPL stock data (modify if needed)\n","df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n","\n","# Convert numeric columns\n","numeric_columns = ['open', 'high', 'low', 'close', 'volume']\n","df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n","\n","# Drop NaN values\n","df = df.dropna()\n","\n","# Normalize features\n","scaler = MinMaxScaler()\n","scaled_data = scaler.fit_transform(df[numeric_columns])\n","\n","# Save the scaler for inverse transformation later\n","with open('/content/drive/MyDrive/mini project/scaler.pkl', 'wb') as f:\n","    pickle.dump(scaler, f)\n","\n","# Define sequence length and time horizons\n","sequence_length = 50\n","time_horizons = [1, 3, 5, 10, 15]\n","\n","# Generate train-test datasets for each T\n","for T in time_horizons:\n","    X, y = [], []\n","\n","    for i in range(len(scaled_data) - sequence_length - T):\n","        X.append(scaled_data[i:i+sequence_length])  # Past 50 timesteps\n","        y.append(scaled_data[i+sequence_length:i+sequence_length+T, 3])  # Next T 'close' prices\n","\n","    X, y = np.array(X), np.array(y)\n","\n","    # Split into training (80%) and testing (20%) sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n","\n","    # Save files for each T-step model\n","    np.save(f\"/content/drive/MyDrive/mini project/X_train_T{T}.npy\", X_train)\n","    np.save(f\"/content/drive/MyDrive/mini project/y_train_T{T}.npy\", y_train)\n","    np.save(f\"/content/drive/MyDrive/mini project/X_test_T{T}.npy\", X_test)\n","    np.save(f\"/content/drive/MyDrive/mini project/y_test_T{T}.npy\", y_test)\n","\n","    print(f\"âœ… Data saved for T={T} steps ahead!\")\n","\n","print(\"ðŸš€ Preprocessing completed! All train & test datasets are ready.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G7dBmNC3bd5V","executionInfo":{"status":"ok","timestamp":1743092923189,"user_tz":-330,"elapsed":8615,"user":{"displayName":"Devarshi Ray","userId":"03035130374243284723"}},"outputId":"df950812-500e-4ad5-c807-aea4c577e901"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-69f9d2451b23>:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n"]},{"output_type":"stream","name":"stdout","text":["âœ… Data saved for T=1 steps ahead!\n","âœ… Data saved for T=3 steps ahead!\n","âœ… Data saved for T=5 steps ahead!\n","âœ… Data saved for T=10 steps ahead!\n","âœ… Data saved for T=15 steps ahead!\n","ðŸš€ Preprocessing completed! All train & test datasets are ready.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import pickle\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Load dataset, skipping first two rows\n","df = pd.read_csv('/content/drive/MyDrive/mini project/stock_data.csv', skiprows=2)\n","\n","# Set column names\n","df.columns = ['ticker', 'date', 'open', 'high', 'low', 'close', 'volume',\n","              'open_jnj', 'high_jnj', 'low_jnj', 'close_jnj', 'volume_jnj',\n","              'open_nke', 'high_nke', 'low_nke', 'close_nke', 'volume_nke']\n","\n","# Convert date column to datetime format\n","df['date'] = pd.to_datetime(df['date'])\n","\n","# Select AAPL stock for now (modify for JNJ or NKE)\n","df = df[['date', 'open', 'high', 'low', 'close', 'volume']]\n","\n","# Convert numeric columns\n","numeric_columns = ['open', 'high', 'low', 'close', 'volume']\n","df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n","\n","# Drop NaN values\n","df = df.dropna()\n","\n","# Apply rolling mean smoothing (window size 3)\n","df['close'] = df['close'].rolling(window=3, min_periods=1).mean()\n","\n","# Normalize only 'close' prices\n","scaler_close = MinMaxScaler()\n","df['close_scaled'] = scaler_close.fit_transform(df[['close']])\n","\n","# Sequence preparation\n","sequence_length = 60\n","X, y = [], []\n","for i in range(len(df) - sequence_length):\n","    X.append(df[['close_scaled']].values[i:i+sequence_length])  # Only close prices\n","    y.append(df['close_scaled'].values[i+sequence_length])\n","\n","X, y = np.array(X), np.array(y)\n","\n","# Save processed data\n","np.save('/content/drive/MyDrive/mini project/X.npy', X)\n","np.save('/content/drive/MyDrive/mini project/y.npy', y)\n","with open('/content/drive/MyDrive/mini project/scaler_close.pkl', 'wb') as f:\n","    pickle.dump(scaler_close, f)\n","\n","print(\"Preprocessed data saved: 'X.npy', 'y.npy', 'scaler_close.pkl'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPY5R_mTjhwm","executionInfo":{"status":"ok","timestamp":1743095698180,"user_tz":-330,"elapsed":3694,"user":{"displayName":"Devarshi Ray","userId":"03035130374243284723"}},"outputId":"a633a0d3-7a43-4929-9f0f-cc4d884805b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessed data saved: 'X.npy', 'y.npy', 'scaler_close.pkl'.\n"]}]}]}